<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--  This file is generated by Nim. -->
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en" data-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>src/pocketflow/llm</title>

<!-- Google fonts -->
<link href='https://fonts.googleapis.com/css?family=Lato:400,600,900' rel='stylesheet' type='text/css'/>
<link href='https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<!-- Favicon -->
<link rel="shortcut icon" href="data:image/x-icon;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAUAAAAF////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAIAAABbAAAAlQAAAKIAAACbAAAAmwAAAKIAAACVAAAAWwAAAAL///8A////AP///wD///8A////AAAAABQAAADAAAAAYwAAAA3///8A////AP///wD///8AAAAADQAAAGMAAADAAAAAFP///wD///8A////AP///wAAAACdAAAAOv///wD///8A////AP///wD///8A////AP///wD///8AAAAAOgAAAJ3///8A////AP///wAAAAAnAAAAcP///wAAAAAoAAAASv///wD///8A////AP///wAAAABKAAAAKP///wAAAABwAAAAJ////wD///8AAAAAgQAAABwAAACIAAAAkAAAAJMAAACtAAAAFQAAABUAAACtAAAAkwAAAJAAAACIAAAAHAAAAIH///8A////AAAAAKQAAACrAAAAaP///wD///8AAAAARQAAANIAAADSAAAARf///wD///8AAAAAaAAAAKsAAACk////AAAAADMAAACcAAAAnQAAABj///8A////AP///wAAAAAYAAAAGP///wD///8A////AAAAABgAAACdAAAAnAAAADMAAAB1AAAAwwAAAP8AAADpAAAAsQAAAE4AAAAb////AP///wAAAAAbAAAATgAAALEAAADpAAAA/wAAAMMAAAB1AAAAtwAAAOkAAAD/AAAA/wAAAP8AAADvAAAA3gAAAN4AAADeAAAA3gAAAO8AAAD/AAAA/wAAAP8AAADpAAAAtwAAAGUAAAA/AAAA3wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAADfAAAAPwAAAGX///8A////AAAAAEgAAADtAAAAvwAAAL0AAADGAAAA7wAAAO8AAADGAAAAvQAAAL8AAADtAAAASP///wD///8A////AP///wD///8AAAAAO////wD///8A////AAAAAIcAAACH////AP///wD///8AAAAAO////wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A//8AAP//AAD4HwAA7/cAAN/7AAD//wAAoYUAAJ55AACf+QAAh+EAAAAAAADAAwAA4AcAAP5/AAD//wAA//8AAA=="/>
<link rel="icon" type="image/png" sizes="32x32" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAAB3RJTUUH4QQQEwksSS9ZWwAAAk1JREFUWMPtll2ITVEUx39nn/O7Y5qR8f05wtCUUr6ZIS++8pEnkZInPImneaCQ5METNdOkeFBKUhMPRIkHKfEuUZSUlGlKPN2TrgfncpvmnntnmlEyq1Z7t89/rf9a6+y99oZxGZf/XeIq61EdtgKXgdXA0xrYAvBjOIF1AI9zvjcC74BSpndrJPkBWDScTF8Aa4E3wDlgHbASaANmVqlcCnwHvgDvgVfAJ+AikAAvgfVZwLnSVZHZaOuKoQi3ZOMi4NkYkpe1p4J7A8BpYAD49hfIy/oqG0+hLomiKP2L5L+1ubn5115S+3OAn4EnwBlgMzCjyt6ZAnQCJ4A7wOs88iRJHvw50HoujuPBoCKwHWiosy8MdfZnAdcHk8dxXFJ3VQbQlCTJvRBCGdRbD4M6uc5glpY3eAihpN5S5w12diSEcCCEcKUO4ljdr15T76ur1FDDLIQQ3qv71EdDOe3Kxj3leRXyk+pxdWnFWod6Wt2bY3de3aSuUHcPBVimHs7mK9WrmeOF6lR1o9qnzskh2ar2qm1qizpfXaPeVGdlmGN5pb09qMxz1Xb1kLqgzn1RyH7JUXW52lr5e/Kqi9qpto7V1atuUzfnARrV7jEib1T76gG2qxdGmXyiekkt1GswPTtek0aBfJp6YySGBfWg2tPQ0FAYgf1stUfdmdcjarbYJEniKIq6gY/Aw+zWHAC+p2labGpqiorFYgGYCEzN7oQdQClN07O1/EfDyGgC0ALMBdYAi4FyK+4H3gLPsxfR1zRNi+NP7nH5J+QntnXe5B5mpfQAAAAASUVORK5CYII=">

<!-- CSS -->
<link rel="stylesheet" type="text/css" href="nimdoc.out.css?v=2.2.6">

<!-- JS -->
<script type="text/javascript" src="dochack.js?v=2.2.6"></script>
</head>
<body>
  <div class="document" id="documentId">
    <div class="container">
      <h1 class="title">src/pocketflow/llm</h1>
      <div class="row">
  <div class="three columns">
    <div class="theme-select-wrapper">
      <label for="theme-select">Theme:&nbsp;</label>
      <select id="theme-select" onchange="setTheme(this.value)">
        <option value="auto">ðŸŒ— Match OS</option>
        <option value="dark">ðŸŒ‘ Dark</option>
        <option value="light">ðŸŒ• Light</option>
      </select>
    </div>
    <div id="global-links">
      <ul class="simple">
        <li><a id="indexLink" href="theindex.html">Index</a></li>
      </ul>
    </div>
    <div id="searchInputDiv">
      Search: <input type="search" id="searchInput" oninput="search()"/>
    </div>
    <div>
      Group by:
      <select onchange="groupBy(this.value)">
        <option value="section">Section</option>
        <option value="type">Type</option>
      </select>
    </div>
    <ul class="simple simple-toc" id="toc-list">
  <li>
  <a class="reference reference-toplevel" href="#6" id="56">Imports</a>
</li>
<li>
  <details open>
    <summary><a class="reference reference-toplevel" href="#7" id="57">Types</a></summary>
    <ul class="simple simple-toc-section">
      <li><a class="reference" href="#LlmClient" title="LlmClient = ref object
  provider*: LlmProvider
  baseUrl*: string
  apiKey*: string
  model*: string
  costTracker*: CostTracker
  cache*: Cache">LlmClient</a></li>
<li><a class="reference" href="#LlmOptions" title="LlmOptions = object
  temperature*: float
  maxTokens*: int
  topP*: float
  stream*: bool
  streamCallback*: StreamCallback
  useCache*: bool
  timeout*: int">LlmOptions</a></li>
<li><a class="reference" href="#LlmProvider" title="LlmProvider = enum
  OpenAI, Ollama, Anthropic, Google, Custom">LlmProvider</a></li>
<li><a class="reference" href="#StreamCallback" title="StreamCallback = proc (chunk: string): Future[void] {.gcsafe.}">StreamCallback</a></li>

    </ul>
  </details>
</li>
<li>
  <details open>
    <summary><a class="reference reference-toplevel" href="#12" id="62">Procs</a></summary>
    <ul class="simple simple-toc-section">
      <ul class="simple nested-toc-section">chat
  <li><a class="reference" href="#chat%2CLlmClient%2CJsonNode%2Cfloat" title="chat(client: LlmClient; messages: JsonNode; temperature: float = 0.7): Future[
    string]">chat(client: LlmClient; messages: JsonNode; temperature: float = 0.7): Future[
    string]</a></li>

</ul>
<ul class="simple nested-toc-section">chatWithOptions
  <li><a class="reference" href="#chatWithOptions%2CLlmClient%2CJsonNode%2CLlmOptions" title="chatWithOptions(client: LlmClient; messages: JsonNode; options: LlmOptions): Future[
    string]">chatWithOptions(client: LlmClient; messages: JsonNode; options: LlmOptions): Future[
    string]</a></li>

</ul>
<ul class="simple nested-toc-section">close
  <li><a class="reference" href="#close%2CLlmClient" title="close(client: LlmClient)">close(client: LlmClient)</a></li>

</ul>
<ul class="simple nested-toc-section">embeddings
  <li><a class="reference" href="#embeddings%2CLlmClient%2Cseq%5Bstring%5D%2Cstring" title="embeddings(client: LlmClient; texts: seq[string]; model: string = &quot;&quot;): Future[
    seq[seq[float]]]">embeddings(client: LlmClient; texts: seq[string]; model: string = &quot;&quot;): Future[
    seq[seq[float]]]</a></li>

</ul>
<ul class="simple nested-toc-section">generate
  <li><a class="reference" href="#generate%2CLlmClient%2Cstring%2Cfloat" title="generate(client: LlmClient; prompt: string; temperature: float = 0.7): Future[
    string]">generate(client: LlmClient; prompt: string; temperature: float = 0.7): Future[
    string]</a></li>

</ul>
<ul class="simple nested-toc-section">newLlmClient
  <li><a class="reference" href="#newLlmClient%2CLlmProvider%2Cstring%2Cstring%2Cstring%2CCostTracker%2CCache" title="newLlmClient(provider: LlmProvider = OpenAI; baseUrl: string = &quot;&quot;;
             apiKey: string = &quot;&quot;; model: string = &quot;&quot;;
             costTracker: CostTracker = nil; cache: Cache = nil): LlmClient">newLlmClient(provider: LlmProvider = OpenAI; baseUrl: string = &quot;&quot;;
             apiKey: string = &quot;&quot;; model: string = &quot;&quot;;
             costTracker: CostTracker = nil; cache: Cache = nil): LlmClient</a></li>

</ul>

    </ul>
  </details>
</li>

</ul>

  </div>
  <div class="nine columns" id="content">
    
    <div id="tocRoot"></div>
    
    <p class="module-desc"><p>LLM client module for PocketFlow</p>
<p>Provides unified interface for multiple LLM providers with streaming, caching, token tracking, and error handling.</p>
</p>
    <div class="section" id="6">
  <h1><a class="toc-backref" href="#6">Imports</a></h1>
  <dl class="item">
    <a class="reference external" href="errors.html">errors</a>, <a class="reference external" href="cache.html">cache</a>, <a class="reference external" href="tokens.html">tokens</a>, <a class="reference external" href="observability.html">observability</a>
  </dl>
</div>
<div class="section" id="7">
  <h1><a class="toc-backref" href="#7">Types</a></h1>
  <dl class="item">
    <div id="LlmClient">
  <dt><pre><a href="llm.html#LlmClient"><span class="Identifier">LlmClient</span></a> <span class="Other">=</span> <span class="Keyword">ref</span> <span class="Keyword">object</span>
  <span class="Identifier">provider</span><span class="Operator">*</span><span class="Other">:</span> <a href="llm.html#LlmProvider"><span class="Identifier">LlmProvider</span></a>
  <span class="Identifier">baseUrl</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">string</span>
  <span class="Identifier">apiKey</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">string</span>
  <span class="Identifier">model</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">string</span>
  <span class="Identifier">costTracker</span><span class="Operator">*</span><span class="Other">:</span> <a href="tokens.html#CostTracker"><span class="Identifier">CostTracker</span></a>
  <span class="Identifier">cache</span><span class="Operator">*</span><span class="Other">:</span> <a href="cache.html#Cache"><span class="Identifier">Cache</span></a></pre></dt>
  <dd>
    
    Client for interacting with LLM providers
    
  </dd>
</div>
<div id="LlmOptions">
  <dt><pre><a href="llm.html#LlmOptions"><span class="Identifier">LlmOptions</span></a> <span class="Other">=</span> <span class="Keyword">object</span>
  <span class="Identifier">temperature</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">float</span>
  <span class="Identifier">maxTokens</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">int</span>
  <span class="Identifier">topP</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">float</span>
  <span class="Identifier">stream</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">bool</span>
  <span class="Identifier">streamCallback</span><span class="Operator">*</span><span class="Other">:</span> <a href="llm.html#StreamCallback"><span class="Identifier">StreamCallback</span></a>
  <span class="Identifier">useCache</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">bool</span>
  <span class="Identifier">timeout</span><span class="Operator">*</span><span class="Other">:</span> <span class="Identifier">int</span></pre></dt>
  <dd>
    
    Configuration options for LLM requests
    
  </dd>
</div>
<div id="LlmProvider">
  <dt><pre><a href="llm.html#LlmProvider"><span class="Identifier">LlmProvider</span></a> <span class="Other">=</span> <span class="Keyword">enum</span>
  <span class="Identifier">OpenAI</span><span class="Other">,</span> <span class="Identifier">Ollama</span><span class="Other">,</span> <span class="Identifier">Anthropic</span><span class="Other">,</span> <span class="Identifier">Google</span><span class="Other">,</span> <span class="Identifier">Custom</span></pre></dt>
  <dd>
    
    Supported LLM providers
    
  </dd>
</div>
<div id="StreamCallback">
  <dt><pre><a href="llm.html#StreamCallback"><span class="Identifier">StreamCallback</span></a> <span class="Other">=</span> <span class="Keyword">proc</span> <span class="Other">(</span><span class="Identifier">chunk</span><span class="Other">:</span> <span class="Identifier">string</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Future</span><span class="Other">[</span><span class="Identifier">void</span><span class="Other">]</span> {.<span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">gcsafe</span></span>.}</pre></dt>
  <dd>
    
    Callback for streaming responses
    
  </dd>
</div>

  </dl>
</div>
<div class="section" id="12">
  <h1><a class="toc-backref" href="#12">Procs</a></h1>
  <dl class="item">
    <div id="chat-procs-all">
  <div id="chat,LlmClient,JsonNode,float">
  <dt><pre><span class="Keyword">proc</span> <a href="#chat%2CLlmClient%2CJsonNode%2Cfloat"><span class="Identifier">chat</span></a><span class="Other">(</span><span class="Identifier">client</span><span class="Other">:</span> <a href="llm.html#LlmClient"><span class="Identifier">LlmClient</span></a><span class="Other">;</span> <span class="Identifier">messages</span><span class="Other">:</span> <span class="Identifier">JsonNode</span><span class="Other">;</span> <span class="Identifier">temperature</span><span class="Other">:</span> <span class="Identifier">float</span> <span class="Other">=</span> <span class="FloatNumber">0.7</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Future</span><span class="Other">[</span>
    <span class="Identifier">string</span><span class="Other">]</span> {.<span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">gcsafe</span><span class="Other">,</span> <span class="Identifier">stackTrace</span><span class="Other">:</span> <span class="DecNumber">false</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">Exception</span><span class="Other">,</span> <span class="Identifier">ValueError</span><span class="Other">]</span><span class="Other">,</span>
              <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">RootEffect</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    <p>Sends a chat completion request (non-streaming)</p>
<p>Args: messages: JArray of message objects with &quot;role&quot; and &quot;content&quot; temperature: Sampling temperature (0.0-2.0)</p>
<p>Returns: The assistant's response text</p>

    
  </dd>
</div>

</div>
<div id="chatWithOptions-procs-all">
  <div id="chatWithOptions,LlmClient,JsonNode,LlmOptions">
  <dt><pre><span class="Keyword">proc</span> <a href="#chatWithOptions%2CLlmClient%2CJsonNode%2CLlmOptions"><span class="Identifier">chatWithOptions</span></a><span class="Other">(</span><span class="Identifier">client</span><span class="Other">:</span> <a href="llm.html#LlmClient"><span class="Identifier">LlmClient</span></a><span class="Other">;</span> <span class="Identifier">messages</span><span class="Other">:</span> <span class="Identifier">JsonNode</span><span class="Other">;</span> <span class="Identifier">options</span><span class="Other">:</span> <a href="llm.html#LlmOptions"><span class="Identifier">LlmOptions</span></a><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Future</span><span class="Other">[</span>
    <span class="Identifier">string</span><span class="Other">]</span> {.<span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">gcsafe</span><span class="Other">,</span> <span class="Identifier">stackTrace</span><span class="Other">:</span> <span class="DecNumber">false</span><span class="Other">,</span>
              <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">Exception</span><span class="Other">,</span> <span class="Identifier">ValueError</span><span class="Other">,</span> <span class="Identifier">KeyError</span><span class="Other">]</span><span class="Other">,</span>
              <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">RootEffect</span><span class="Other">,</span> <span class="Identifier">TimeEffect</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    
    
  </dd>
</div>

</div>
<div id="close-procs-all">
  <div id="close,LlmClient">
  <dt><pre><span class="Keyword">proc</span> <a href="#close%2CLlmClient"><span class="Identifier">close</span></a><span class="Other">(</span><span class="Identifier">client</span><span class="Other">:</span> <a href="llm.html#LlmClient"><span class="Identifier">LlmClient</span></a><span class="Other">)</span> {.<span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">LibraryError</span><span class="Other">,</span> <span class="Identifier">Exception</span><span class="Other">,</span> <span class="Identifier">SslError</span><span class="Other">]</span><span class="Other">,</span>
                                <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">RootEffect</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    Closes the HTTP client and releases resources
    
  </dd>
</div>

</div>
<div id="embeddings-procs-all">
  <div id="embeddings,LlmClient,seq[string],string">
  <dt><pre><span class="Keyword">proc</span> <a href="#embeddings%2CLlmClient%2Cseq%5Bstring%5D%2Cstring"><span class="Identifier">embeddings</span></a><span class="Other">(</span><span class="Identifier">client</span><span class="Other">:</span> <a href="llm.html#LlmClient"><span class="Identifier">LlmClient</span></a><span class="Other">;</span> <span class="Identifier">texts</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">string</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">model</span><span class="Other">:</span> <span class="Identifier">string</span> <span class="Other">=</span> <span class="StringLit">&quot;&quot;</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Future</span><span class="Other">[</span>
    <span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">seq</span><span class="Other">[</span><span class="Identifier">float</span><span class="Other">]</span><span class="Other">]</span><span class="Other">]</span> {.<span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">gcsafe</span><span class="Other">,</span> <span class="Identifier">stackTrace</span><span class="Other">:</span> <span class="DecNumber">false</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">Exception</span><span class="Other">,</span>
    <span class="Identifier">ValueError</span><span class="Other">,</span> <span class="Identifier">LLMError</span><span class="Other">,</span> <span class="Identifier">KeyError</span><span class="Other">,</span> <span class="Identifier">HttpRequestError</span><span class="Other">,</span> <span class="Identifier">LibraryError</span><span class="Other">,</span> <span class="Identifier">SslError</span><span class="Other">,</span>
    <span class="Identifier">OSError</span><span class="Other">,</span> <span class="Identifier">IOError</span><span class="Other">,</span> <span class="Identifier">ProtocolError</span><span class="Other">,</span> <span class="Identifier">JsonParsingError</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">RootEffect</span><span class="Other">,</span>
    <span class="Identifier">TimeEffect</span><span class="Other">,</span> <span class="Identifier">ReadIOEffect</span><span class="Other">,</span> <span class="Identifier">WriteIOEffect</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    <p>Generates embeddings for text inputs</p>
<p>Args: texts: Sequence of texts to embed model: Embedding model (uses defaults if empty)</p>
<p>Returns: Sequence of embedding vectors</p>

    
  </dd>
</div>

</div>
<div id="generate-procs-all">
  <div id="generate,LlmClient,string,float">
  <dt><pre><span class="Keyword">proc</span> <a href="#generate%2CLlmClient%2Cstring%2Cfloat"><span class="Identifier">generate</span></a><span class="Other">(</span><span class="Identifier">client</span><span class="Other">:</span> <a href="llm.html#LlmClient"><span class="Identifier">LlmClient</span></a><span class="Other">;</span> <span class="Identifier">prompt</span><span class="Other">:</span> <span class="Identifier">string</span><span class="Other">;</span> <span class="Identifier">temperature</span><span class="Other">:</span> <span class="Identifier">float</span> <span class="Other">=</span> <span class="FloatNumber">0.7</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Future</span><span class="Other">[</span>
    <span class="Identifier">string</span><span class="Other">]</span> {.<span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">gcsafe</span><span class="Other">,</span> <span class="Identifier">stackTrace</span><span class="Other">:</span> <span class="DecNumber">false</span><span class="Other">,</span> <span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">Exception</span><span class="Other">,</span> <span class="Identifier">ValueError</span><span class="Other">]</span><span class="Other">,</span>
              <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Identifier">RootEffect</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    <p>Helper for simple single-turn generation</p>
<p>Args: prompt: The user prompt temperature: Sampling temperature</p>
<p>Returns: The generated response</p>

    
  </dd>
</div>

</div>
<div id="newLlmClient-procs-all">
  <div id="newLlmClient,LlmProvider,string,string,string,CostTracker,Cache">
  <dt><pre><span class="Keyword">proc</span> <a href="#newLlmClient%2CLlmProvider%2Cstring%2Cstring%2Cstring%2CCostTracker%2CCache"><span class="Identifier">newLlmClient</span></a><span class="Other">(</span><span class="Identifier">provider</span><span class="Other">:</span> <a href="llm.html#LlmProvider"><span class="Identifier">LlmProvider</span></a> <span class="Other">=</span> <span class="Identifier">OpenAI</span><span class="Other">;</span> <span class="Identifier">baseUrl</span><span class="Other">:</span> <span class="Identifier">string</span> <span class="Other">=</span> <span class="StringLit">&quot;&quot;</span><span class="Other">;</span>
                  <span class="Identifier">apiKey</span><span class="Other">:</span> <span class="Identifier">string</span> <span class="Other">=</span> <span class="StringLit">&quot;&quot;</span><span class="Other">;</span> <span class="Identifier">model</span><span class="Other">:</span> <span class="Identifier">string</span> <span class="Other">=</span> <span class="StringLit">&quot;&quot;</span><span class="Other">;</span>
                  <span class="Identifier">costTracker</span><span class="Other">:</span> <a href="tokens.html#CostTracker"><span class="Identifier">CostTracker</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">;</span> <span class="Identifier">cache</span><span class="Other">:</span> <a href="cache.html#Cache"><span class="Identifier">Cache</span></a> <span class="Other">=</span> <span class="Keyword">nil</span><span class="Other">)</span><span class="Other">:</span> <a href="llm.html#LlmClient"><span class="Identifier">LlmClient</span></a> {.
    <span><span class="Other pragmadots">...</span></span><span class="pragmawrap"><span class="Identifier">raises</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">tags</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span><span class="Other">,</span> <span class="Identifier">forbids</span><span class="Other">:</span> <span class="Other">[</span><span class="Other">]</span></span>.}</pre></dt>
  <dd>
    
    <p>Creates a new LLM client</p>
<p>Args: provider: The LLM provider to use baseUrl: Custom base URL (uses defaults if empty) apiKey: API key for authentication model: Model name (uses defaults if empty) costTracker: Optional custom cost tracker cache: Optional custom cache</p>

    
  </dd>
</div>

</div>

  </dl>
</div>

  </div>
</div>

      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br>
        <small style="color: var(--hint);">Made with Nim. Generated: 2026-01-07 00:32:53 UTC</small>
      </div>
    </div>
  </div>
  
</body>
</html>
